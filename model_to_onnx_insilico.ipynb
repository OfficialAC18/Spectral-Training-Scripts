{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'insilico_conv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mort\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minsilico_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InSilicoConv\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minsilico_lrcn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InSilicoLRCN\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minsilico_lstm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InSilicoLSTM\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'insilico_conv'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import json\n",
    "import torch\n",
    "from torch import onnx\n",
    "import torch.nn.functional as F\n",
    "import onnxruntime as ort\n",
    "from insilico_conv import InSilicoConv\n",
    "from insilico_lrcn import InSilicoLRCN\n",
    "from insilico_lstm import InSilicoLSTM\n",
    "from captum.attr import KernelShap, GradientShap\n",
    "from SpecReX.wrapper import SReX\n",
    "\n",
    "\n",
    "import shap\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.backends.cudnn.enabled=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Simulated Spectral Dataset/Mean Spectra/single_peak_class_0_mean.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#For testing \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m single_peak_0 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../Simulated Spectral Dataset/Mean Spectra/single_peak_class_0_mean.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m single_peak_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Simulated Spectral Dataset/Mean Spectra/single_peak_class_1_mean.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m single_peak_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Simulated Spectral Dataset/Mean Spectra/single_peak_class_2_mean.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Simulated Spectral Dataset/Mean Spectra/single_peak_class_0_mean.npy'"
     ]
    }
   ],
   "source": [
    "#For testing \n",
    "single_peak_0 = np.load('../Simulated Spectral Dataset/Mean Spectra/single_peak_class_0_mean.npy')\n",
    "single_peak_1 = np.load('../Simulated Spectral Dataset/Mean Spectra/single_peak_class_1_mean.npy')\n",
    "single_peak_2 = np.load('../Simulated Spectral Dataset/Mean Spectra/single_peak_class_2_mean.npy')\n",
    "\n",
    "double_peak_0 = np.load('../Simulated Spectral Dataset/Mean Spectra/double_peak_class_0_mean.npy')\n",
    "double_peak_1 = np.load('../Simulated Spectral Dataset/Mean Spectra/double_peak_class_1_mean.npy')\n",
    "double_peak_2 = np.load('../Simulated Spectral Dataset/Mean Spectra/double_peak_class_2_mean.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Simulated Spectral Dataset/Single Peak/Train/train20260_class0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#For Background\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m background_class_0_single \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../Simulated Spectral Dataset/Single Peak/Train/train20260_class0.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m background_class_1_single \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Simulated Spectral Dataset/Single Peak/Train/train3155_class1.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m background_class_2_single \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Simulated Spectral Dataset/Single Peak/Train/train42360_class2.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Simulated Spectral Dataset/Single Peak/Train/train20260_class0.npy'"
     ]
    }
   ],
   "source": [
    "#For Background\n",
    "background_class_0_single = np.load('../Simulated Spectral Dataset/Single Peak/Train/train20260_class0.npy')\n",
    "background_class_1_single = np.load('../Simulated Spectral Dataset/Single Peak/Train/train3155_class1.npy')\n",
    "background_class_2_single = np.load('../Simulated Spectral Dataset/Single Peak/Train/train42360_class2.npy')\n",
    "\n",
    "backgroud_class_0_double = np.load('../Simulated Spectral Dataset/Double Peak/Train/train3157_class0.npy')\n",
    "background_class_1_double = np.load('../Simulated Spectral Dataset/Double Peak/Train/train53175_class1.npy')\n",
    "background_class_2_double = np.load('../Simulated Spectral Dataset/Double Peak/Train/train4237_class2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = x.reshape(1,1,-1).astype(np.float32)\n",
    "    return softmax(np.array(ort_sess.run(None, {'input': x}))).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = torch.from_numpy(x.reshape(1,1,-1).astype(np.float32)).cuda()\n",
    "    return softmax(model(x).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return x * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_non_zero(x):\n",
    "    current_val = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != 0:\n",
    "            current_val = x[i]\n",
    "        else:\n",
    "            x[i] = current_val\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Peak Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k23058970/miniforge3/envs/Training/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Single Peak Conv Null/tune_with_parameters_2024-08-19_13-25-03/tune_with_parameters_21b89_00001_1_dp=0.2000,k1=7,k2=1,k3=3,k4=1,lr=0.0426_2024-08-19_13-25-34/checkpoint_000002/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = InSilicoConv(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.1,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,852)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "# Creating a representative input\n",
    "batch_size = 32\n",
    "x = torch.rand(batch_size,1,852, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/single_peak_conv.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "srex = SReX(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectra Classified as %s [2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed = %d 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43msrex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_responsibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectra\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msingle_peak_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msingle_peak_0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/SpecReX/wrapper.py:126\u001b[0m, in \u001b[0;36mSReX.calc_responsibility\u001b[0;34m(self, spectra, wn, iters, seed, distribution, distribution_args, tree_depth, min_box_size, min_work, interp_method, weighted, search_limit, bounding_box, total_restart_attempts, targets)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterp_method \u001b[38;5;241m=\u001b[39m interp_method\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#Calculate the responsibility\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m \u001b[43mexplanation_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspectra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwn_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribution_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_box_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_box_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterp_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterp_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_work\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_work\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_restart_attempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_restart_attempts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounding_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtargets\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#Calculate the summaries of the responsibility landscape\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpmax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpmax_pos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpstd_dev, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpmedian \u001b[38;5;241m=\u001b[39m summarise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresp)\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/SpecReX/explanation.py:144\u001b[0m, in \u001b[0;36mexplanation_wrapper\u001b[0;34m(prediction_func, spec_array, wn_array, spec_shape, iters, distribution, distribution_args, search_limit, tree_depth, weighted, min_box_size, interp_method, min_work, total_restart_attempts, seed, bounding_box, targets)\u001b[0m\n\u001b[1;32m    142\u001b[0m resp_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(iters):\n\u001b[0;32m--> 144\u001b[0m     r, p, f, dr, avg_size \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_explanation_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mspec_array\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspec_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mwn_array\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwn_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mspec_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspec_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdistribution_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdistribution_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43msearch_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msearch_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtree_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtree_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmin_box_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_box_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43minterp_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterp_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mresponsibility_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresp_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmin_work\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_work\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtotal_restart_attempts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_restart_attempts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mrepeated\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mprediction_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprediction_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbounding_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     resp_map \u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    164\u001b[0m     passing \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m p\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/SpecReX/responsibility.py:398\u001b[0m, in \u001b[0;36mcausal_explanation_wrapper\u001b[0;34m(process, spec_array, wn_array, spec_shape, distribution, distribution_args, search_limit, tree_depth, targets, weighted, min_box_size, interp_method, responsibility_map, min_work, total_restart_attempts, repeated, seed, prediction_func, bounding_box)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     tree \u001b[38;5;241m=\u001b[39m initialise_tree(spec_shape\u001b[38;5;241m.\u001b[39mlength, distribution, distribution_args)\n\u001b[0;32m--> 398\u001b[0m \u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_box_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m total_work \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    401\u001b[0m total_passing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/SpecReX/box.py:176\u001b[0m, in \u001b[0;36mbuild_tree\u001b[0;34m(root, depth, min_size)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m PreOrderIter(root):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m depth \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(n\u001b[38;5;241m.\u001b[39mchildren) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m         \u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_children_to_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/SpecReX/box.py:150\u001b[0m, in \u001b[0;36mBox.add_children_to_tree\u001b[0;34m(self, min_size)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_children_to_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m, min_size):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren:\n\u001b[0;32m--> 150\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Training/lib/python3.10/site-packages/SpecReX/box.py:58\u001b[0m, in \u001b[0;36mBoxInternal.spawn_children\u001b[0;34m(self, min_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m     57\u001b[0m row_mid \u001b[38;5;241m=\u001b[39m random_pos(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_start, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_stop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_args])\n\u001b[0;32m---> 58\u001b[0m row_lt \u001b[38;5;241m=\u001b[39m random_pos(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_start, \u001b[43mrow_mid\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_args])\n\u001b[1;32m     59\u001b[0m row_gt \u001b[38;5;241m=\u001b[39m random_pos(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution, [row_mid\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_stop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_args])\n\u001b[1;32m     61\u001b[0m children \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "resp = srex.calc_responsibility(spectra = single_peak_0.reshape(1,-1), wn = np.arange(len(single_peak_0)).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(single_peak_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['conv4.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['conv4.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PyTorch model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('Class 0:',F.softmax(model(torch.Tensor(single_peak_0.astype(np.float64)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 1:',F.softmax(model(torch.Tensor(single_peak_1.astype(np.float64)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 2:',F.softmax(model(torch.Tensor(single_peak_2.astype(np.float64)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_conv.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': single_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': single_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': single_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = partial(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ks = KernelShap(model)\n",
    "attr_ks = ks.attribute(torch.from_numpy(single_peak_0.reshape(1,1,-1).astype(np.float32)).cuda(), target = 0, n_samples=10000).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs = GradientShap(model)\n",
    "attr_gs = gs.attribute(torch.from_numpy(single_peak_2.reshape(1,1,-1).astype(np.float32)).cuda(), torch.zeros(1,1,852).cuda(), target = 2, n_samples = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1,\n",
    "                       ncols=1,\n",
    "                       figsize=(15,6))\n",
    "\n",
    "shap_vals = ReLU(attr_ks.detach().cpu().numpy().reshape(-1))\n",
    "\n",
    "axs.plot(np.abs(shap_vals) / np.max(np.abs(shap_vals)))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_vals) / np.max(np.abs(shap_vals))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_vals):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_2, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating SHAP\n",
    "\n",
    "# # Sample background data from the reshaped tensor\n",
    "background_indices = np.random.choice(single_peak_0.shape[0], 852, replace=True)\n",
    "background = np.zeros(shape = (1,852))\n",
    "\n",
    "\n",
    "explainer_class_0 = shap.DeepExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_1 = shap.DeepExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_2 = shap.DeepExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "\n",
    "shap_values_class_0 = explainer_class_0.shap_values(torch.from_numpy(single_peak_0.reshape(1,1,-1).astype(np.float32)).cuda()).reshape(852,-1)[:,0]\n",
    "shap_values_class_1 = explainer_class_1.shap_values(torch.from_numpy(single_peak_1.reshape(1,1,-1).astype(np.float32)).cuda()).reshape(852,-1)[:,1]\n",
    "shap_values_class_2 = explainer_class_2.shap_values(torch.from_numpy(single_peak_2.reshape(1,1,-1).astype(np.float32)).cuda()).reshape(852,-1)[:,2]\n",
    "\n",
    "shap_values_class_0.shape, shap_values_class_1.shape, shap_values_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_peak_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_0) / np.max(np.abs(shap_values_class_0))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_0):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_0, label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 1')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,\n",
    "                       ncols=1,\n",
    "                       figsize=(15,12))\n",
    "\n",
    "axs[0].plot(ReLU(shap_values_class_0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_1):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_1, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1,\n",
    "                       ncols=1,\n",
    "                       figsize=(12,6))\n",
    "\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "axs.plot(magnitude)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_2) / np.max(np.abs(shap_values_class_2))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_2):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_2, label='Class 3 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 3')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,\n",
    "                       ncols=1,\n",
    "                       figsize=(15,12))\n",
    "\n",
    "axs[0].plot(ReLU(shap_values_class_2))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(shap_values_class_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Peak LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k23058970/miniforge3/envs/Training/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4661: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Single Peak LRCN Null/tune_with_parameters_2024-08-19_13-29-31/tune_with_parameters_c1630_00004_4_dp=0.2500,k1=1,k2=5,k3=1,k4=5,lr=0.0873_2024-08-19_13-30-01/checkpoint_000001/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = InSilicoLRCN(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,852)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,852, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/single_peak_lrcn.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "with torch.no_grad():\n",
    "    print('Class 0:',F.softmax(model(torch.Tensor(single_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 1:',F.softmax(model(torch.Tensor(single_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 2:',F.softmax(model(torch.Tensor(single_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values\n",
    "ks = KernelShap(model)\n",
    "attr_ks = ks.attribute(torch.from_numpy(single_peak_0.reshape(1,1,-1).astype(np.float32)).cuda(), target = 0, n_samples=2000, show_progress = True).reshape(-1)\n",
    "shap_vals = ReLU(attr_ks.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,\n",
    "                       ncols=1,\n",
    "                       figsize=(15,12))\n",
    "\n",
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_vals) / np.max(np.abs(shap_vals))\n",
    "\n",
    "axs[0].plot(shap_vals, color ='black')\n",
    "axs[0].set_title('Saliency Landscape')\n",
    "axs[0].set_xlabel('Wavenumber')\n",
    "axs[0].set_ylabel('Intensity (A.U.)')\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_vals):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    axs[1].axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "axs[1].plot(single_peak_0, label='Class 0 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "axs[1].set_title('SHAP Values and Spectrum for Class 0')\n",
    "axs[1].set_xlabel('Wavenumber')\n",
    "axs[1].set_ylabel('Intensity (A.U.)')\n",
    "axs[1].grid(True)  # Optionally add grid for better visual tracking of features\n",
    "\n",
    "fig.savefig('SHAP Saliency Landscape CNN class 0.png',\n",
    "        dpi = 900,\n",
    "        bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_vals):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_2, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_lrcn.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': single_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': single_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': single_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating SHAP\n",
    "\n",
    "# # Sample background data from the reshaped tensor\n",
    "background_indices = np.random.choice(single_peak_0.shape[0], 852, replace=True)\n",
    "background = np.zeros(shape = (1,852))\n",
    "\n",
    "model.train()\n",
    "\n",
    "explainer_class_0 = shap.KernelExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_1 = shap.KernelExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_2 = shap.KernelExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "\n",
    "shap_values_class_0 = explainer_class_0.shap_values(torch.from_numpy(single_peak_0.reshape(1,1,-1).astype(np.float32)).cuda()).reshape(852,-1)[:,0]\n",
    "shap_values_class_1 = explainer_class_1.shap_values(torch.from_numpy(single_peak_1.reshape(1,1,-1).astype(np.float32)).cuda()).reshape(852,-1)[:,1]\n",
    "shap_values_class_2 = explainer_class_2.shap_values(torch.from_numpy(single_peak_2.reshape(1,1,-1).astype(np.float32)).cuda()).reshape(852,-1)[:,2]\n",
    "\n",
    "shap_values_class_0.shape, shap_values_class_1.shape, shap_values_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_0) / np.max(np.abs(shap_values_class_0))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_0):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_0, label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 1')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_1):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_1, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_2) / np.max(np.abs(shap_values_class_2))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_2):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_2, label='Class 3 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 3')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Peak LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Single Peak LSTM Null/tune_with_parameters_2024-08-19_13-32-44/tune_with_parameters_3497d_00000_0_dp=0.2000,hidden_size=400,lr=0.0022,num_layers=1_2024-08-19_13-33-15/checkpoint_000021/checkpoint.pt')\n",
    "\n",
    "# #Load Model\n",
    "model = InSilicoLSTM(\n",
    "    hidden_size=400,\n",
    "    num_layers=1,\n",
    "    dp=0.1,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,852)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "# #Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,852, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/single_peak_lstm.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "with torch.no_grad():\n",
    "    print('Class 0:',F.softmax(model(torch.Tensor(single_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 1:',F.softmax(model(torch.Tensor(single_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 2:',F.softmax(model(torch.Tensor(single_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_lstm.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': single_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': single_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': single_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating SHAP\n",
    "\n",
    "# # Sample background data from the reshaped tensor\n",
    "background_indices = np.random.choice(single_peak_0.shape[0], 852, replace=True)\n",
    "background = np.zeros(shape = (1,852))\n",
    "\n",
    "model.train()\n",
    "\n",
    "explainer_class_0 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_1 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_2 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "\n",
    "shap_values_class_0 = explainer_class_0.shap_values(torch.from_numpy(single_peak_0.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,0]\n",
    "shap_values_class_1 = explainer_class_1.shap_values(torch.from_numpy(single_peak_1.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,1]\n",
    "shap_values_class_2 = explainer_class_2.shap_values(torch.from_numpy(single_peak_2.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,2]\n",
    "\n",
    "shap_values_class_0.shape, shap_values_class_1.shape, shap_values_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_0) / np.max(np.abs(shap_values_class_0))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_0):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_0, label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 1')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_1):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_1, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_2) / np.max(np.abs(shap_values_class_2))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_2):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(single_peak_1, label='Class 3 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 3')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Peak Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Double Peak Conv Null/tune_with_parameters_347d1_00000_0_dp=0.2500,k1=1,k2=5,k3=5,k4=5,lr=0.0525_2024-08-19_21-54-19/checkpoint_000007/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = InSilicoConv(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.1,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,852)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,852, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/double_peak_conv_null.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "with torch.no_grad():\n",
    "    print('Class 0:',F.softmax(model(torch.Tensor(double_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 1:',F.softmax(model(torch.Tensor(double_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 2:',F.softmax(model(torch.Tensor(double_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/double_peak_conv.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': double_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': double_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': double_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating SHAP\n",
    "\n",
    "# # Sample background data from the reshaped tensor\n",
    "background_indices = np.random.choice(single_peak_0.shape[0], 852, replace=True)\n",
    "background = np.zeros(shape = (1,852))\n",
    "\n",
    "\n",
    "explainer_class_0 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_1 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_2 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "\n",
    "shap_values_class_0 = explainer_class_0.shap_values(torch.from_numpy(double_peak_0.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,0]\n",
    "shap_values_class_1 = explainer_class_1.shap_values(torch.from_numpy(double_peak_1.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,1]\n",
    "shap_values_class_2 = explainer_class_2.shap_values(torch.from_numpy(double_peak_2.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,2]\n",
    "\n",
    "shap_values_class_0.shape, shap_values_class_1.shape, shap_values_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_0) / np.max(np.abs(shap_values_class_0))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_0):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_0, label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 1')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_1):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_1, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_2) / np.max(np.abs(shap_values_class_2))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_2):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_2, label='Class 3 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 3')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Peak LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Double Peak LRCN Null/tune_with_parameters_54ae7_00002_2_dp=0.2500,k1=5,k2=3,k3=3,k4=1,lr=0.0141_2024-08-19_21-55-13/checkpoint_000018/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = InSilicoLRCN(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,852)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,852, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/double_peak_lrcn_null.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "with torch.no_grad():\n",
    "    print('Class 0:',F.softmax(model(torch.Tensor(double_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 1:',F.softmax(model(torch.Tensor(double_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "    print('Class 2:',F.softmax(model(torch.Tensor(double_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/double_peak_lrcn.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': double_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': double_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': double_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating SHAP\n",
    "\n",
    "# # Sample background data from the reshaped tensor\n",
    "background_indices = np.random.choice(single_peak_0.shape[0], 852, replace=True)\n",
    "background = np.zeros(shape = (1,852))\n",
    "\n",
    "\n",
    "explainer_class_0 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_1 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_2 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "\n",
    "shap_values_class_0 = explainer_class_0.shap_values(torch.from_numpy(double_peak_0.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,0]\n",
    "shap_values_class_1 = explainer_class_1.shap_values(torch.from_numpy(double_peak_1.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,1]\n",
    "shap_values_class_2 = explainer_class_2.shap_values(torch.from_numpy(double_peak_2.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,2]\n",
    "\n",
    "shap_values_class_0.shape, shap_values_class_1.shape, shap_values_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_0) / np.max(np.abs(shap_values_class_0))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_0):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_0, label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 1')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_1):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_1, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_2) / np.max(np.abs(shap_values_class_2))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_2):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_2, label='Class 3 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 3')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Peak LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Double Peak LSTM Null/tune_with_parameters_34c49_00004_4_dp=0.1000,hidden_size=500,lr=0.0013,num_layers=1_2024-08-19_22-08-39/checkpoint_000025/checkpoint.pt')\n",
    "\n",
    "# #Load Model\n",
    "model = InSilicoLSTM(\n",
    "    hidden_size=500,\n",
    "    num_layers=1,\n",
    "    dp=0.1,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,852)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "# #Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,852, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/double_peak_lstm_null.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values\n",
    "ks = KernelShap(model)\n",
    "attr_ks = ks.attribute(torch.from_numpy(double_peak_2.reshape(1,1,-1).astype(np.float32)).cuda(), target = 2, n_samples=2000, show_progress = True).reshape(-1)\n",
    "shap_vals = ReLU(attr_ks.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,\n",
    "                       ncols=1,\n",
    "                       figsize=(15,12))\n",
    "\n",
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_vals) / np.max(np.abs(shap_vals))\n",
    "\n",
    "axs[0].plot(shap_vals, color ='black')\n",
    "axs[0].set_title('Saliency Landscape')\n",
    "axs[0].set_xlabel('Wavenumber')\n",
    "axs[0].set_ylabel('Intensity (A.U.)')\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_vals):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    axs[1].axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "axs[1].plot(double_peak_2.reshape(-1), label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "axs[1].set_title('SHAP Values and Spectrum for Class 2')\n",
    "axs[1].set_xlabel('Wavenumber')\n",
    "axs[1].set_ylabel('Intensity (A.U.)')\n",
    "axs[1].grid(True)  # Optionally add grid for better visual tracking of features\n",
    "\n",
    "fig.savefig('SHAP Saliency Landscape LSTM class 2.png',\n",
    "        dpi = 900,\n",
    "        bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "print('Class 0:',F.softmax(model(torch.Tensor(double_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 1:',F.softmax(model(torch.Tensor(double_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 2:',F.softmax(model(torch.Tensor(double_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_conv.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': double_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': double_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': double_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating SHAP\n",
    "\n",
    "# # Sample background data from the reshaped tensor\n",
    "background_indices = np.random.choice(single_peak_0.shape[0], 852, replace=True)\n",
    "background = np.zeros(shape = (1,852))\n",
    "\n",
    "\n",
    "explainer_class_0 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_1 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "explainer_class_2 = shap.GradientExplainer(model, torch.from_numpy(background.reshape(1,1,-1).astype(np.float32)).cuda())\n",
    "\n",
    "shap_values_class_0 = explainer_class_0.shap_values(torch.from_numpy(double_peak_0.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,0]\n",
    "shap_values_class_1 = explainer_class_1.shap_values(torch.from_numpy(double_peak_1.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,1]\n",
    "shap_values_class_2 = explainer_class_2.shap_values(torch.from_numpy(double_peak_2.reshape(1,1,-1)).cuda()).reshape(852,-1)[:,2]\n",
    "\n",
    "shap_values_class_0.shape, shap_values_class_1.shape, shap_values_class_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_0) / np.max(np.abs(shap_values_class_0))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_0):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_0, label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 1')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_1) / np.max(np.abs(shap_values_class_1))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_1):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_1, label='Class 2 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 2')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_values_class_2) / np.max(np.abs(shap_values_class_2))\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_values_class_2):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    plt.axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "plt.plot(double_peak_2, label='Class 3 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "plt.title('SHAP Values and Spectrum for Class 3')\n",
    "plt.xlabel('Wavenumber shift')\n",
    "plt.ylabel('Intensity (A.U.)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Optionally add grid for better visual tracking of features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Peak Cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Complex Peak Conv Null/tune_with_parameters_b687f_00000_0_dp=0.1000,k1=1,k2=5,k3=3,k4=5,lr=0.0160_2024-08-19_22-55-13/checkpoint_000001/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = InSilicoConv(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.1,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,1752)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,1752, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/complex_peak_conv_null.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "print('Class 0:',F.softmax(model(torch.Tensor(single_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 1:',F.softmax(model(torch.Tensor(single_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 2:',F.softmax(model(torch.Tensor(single_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_conv.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': single_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': single_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': single_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Peak LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Complex Peak LRCN Null/tune_with_parameters_a4509_00001_1_dp=0.2000,k1=5,k2=1,k3=5,k4=5,lr=0.0679_2024-08-19_22-54-43/checkpoint_000006/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = InSilicoLRCN(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.25,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,1752)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,1752, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/complex_peak_lrcn_null.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "print('Class 0:',F.softmax(model(torch.Tensor(single_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 1:',F.softmax(model(torch.Tensor(single_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 2:',F.softmax(model(torch.Tensor(single_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_conv.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': single_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': single_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': single_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Peak LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#F1-score: 0.84\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/Complex Peak LSTM Null/tune_with_parameters_cf806_00007_7_dp=0.2000,hidden_size=200,lr=0.0462,num_layers=1_2024-08-19_22-55-55/checkpoint_000006/checkpoint.pt')\n",
    "\n",
    "# #Load Model\n",
    "model = InSilicoLSTM(\n",
    "    hidden_size=200,\n",
    "    num_layers=1,\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,1752)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "# #Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,1752, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/complex_peak_lstm_null.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state['fc2.weight'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_peak_class_1 = np.load(\"../ComplexPeakClass_1 Mean 1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP Values\n",
    "ks = KernelShap(model)\n",
    "attr_ks = ks.attribute(torch.from_numpy(complex_peak_class_1.reshape(1,1,-1).astype(np.float32)).cuda(), target = 2, n_samples=2000, show_progress = True).reshape(-1)\n",
    "shap_vals = ReLU(attr_ks.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,\n",
    "                       ncols=1,\n",
    "                       figsize=(15,12))\n",
    "\n",
    "# Normalize the magnitude of SHAP values to determine the color intensity\n",
    "magnitude = np.abs(shap_vals) / np.max(np.abs(shap_vals))\n",
    "\n",
    "axs[0].plot(shap_vals, color ='black')\n",
    "axs[0].set_title('Saliency Landscape')\n",
    "axs[0].set_xlabel('Wavenumber')\n",
    "axs[0].set_ylabel('Intensity (A.U.)')\n",
    "\n",
    "# Plot SHAP values as colored vertical lines across the entire y-axis\n",
    "for i, value in enumerate(shap_vals):\n",
    "    color = 'red' if value > 0 else 'blue'\n",
    "    alpha = magnitude[i]\n",
    "    axs[1].axvline(x=i, color=color, alpha=alpha, linewidth=2)\n",
    "\n",
    "# Overlay the test sample spectrum as a line plot\n",
    "axs[1].plot(complex_peak_class_1.reshape(-1), label='Class 1 Mean', color='black', linewidth=1.5)\n",
    "\n",
    "# Enhance the plot\n",
    "axs[1].set_title('SHAP Values and Spectrum for Class 1')\n",
    "axs[1].set_xlabel('Wavenumber')\n",
    "axs[1].set_ylabel('Intensity (A.U.)')\n",
    "axs[1].grid(True)  # Optionally add grid for better visual tracking of features\n",
    "\n",
    "fig.savefig('SHAP Saliency Landscape LSTM class 1.png',\n",
    "        dpi = 900,\n",
    "        bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PyTorch model\n",
    "print('Class 0:',F.softmax(model(torch.Tensor(single_peak_0.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 1:',F.softmax(model(torch.Tensor(single_peak_1.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))\n",
    "print('Class 2:',F.softmax(model(torch.Tensor(single_peak_2.astype(np.float32)).to('cuda').reshape(1,1,-1)),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ONNX model \n",
    "ort_sess = ort.InferenceSession('Final Models/single_peak_conv.onnx')\n",
    "output_class_0 = ort_sess.run(None, {'input': single_peak_0.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_1 = ort_sess.run(None, {'input': single_peak_1.reshape(1,1,-1).astype(np.float32)})\n",
    "output_class_2 = ort_sess.run(None, {'input': single_peak_2.reshape(1,1,-1).astype(np.float32)})\n",
    "\n",
    "print('Class 0 ONNX:',softmax(output_class_0, axis=-1))\n",
    "print('Class 1 ONNX:',softmax(output_class_1, axis=-1))\n",
    "print('Class 2 ONNX:',softmax(output_class_2, axis=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
