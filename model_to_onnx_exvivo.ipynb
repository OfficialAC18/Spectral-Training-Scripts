{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import onnx\n",
    "from exvivo_conv import ExVivoConv\n",
    "from exvivo_lrcn import ExVivoLRCN\n",
    "from exvivo_lstm import ExVivoLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Class Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/SMART All Class Conv/tune_with_parameters_4d824_00000_0_dp=0.2000,k1=5,k2=1,k3=7,k4=1,lr=0.0616_2024-07-28_16-37-31/checkpoint_000004/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = ExVivoConv(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "# Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/all_class_conv.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Class LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k23058970/miniforge3/envs/Training/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4661: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/SMART All Class LRCN/tune_with_parameters_49b4d_00007_7_dp=0.2000,k1=1,k2=3,k3=1,k4=1,lr=0.0475_2024-07-28_16-23-06/checkpoint_000006/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = ExVivoLRCN(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/all_class_lrcn.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Class LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/SMART All Class LSTM/tune_with_parameters_ece71_00004_4_dp=0.1000,hidden_size=100,lr=0.0720,num_layers=2_2024-07-28_16-27-40/checkpoint_000008/checkpoint.pt')\n",
    "\n",
    "# #Load Model\n",
    "model = ExVivoLSTM(\n",
    "    hidden_size=100,\n",
    "    num_layers=2,\n",
    "    dp=0.1,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "# #Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/all_class_lstm.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSQ vs AC Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exvivo_two_class_conv import ExVivoConv\n",
    "from exvivo_two_class_lrcn import ExVivoLRCN\n",
    "from exvivo_two_class_lstm import ExVivoLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/NSQ vs AC Conv/tune_with_parameters_471cf_00007_7_dp=0.2000,k1=7,k2=5,k3=1,k4=3,lr=0.0626_2024-07-29_17-04-47/checkpoint_000008/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = ExVivoConv(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/NSQ_AC_conv.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSQ vs AC LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/NSQ vs AC LRCN/tune_with_parameters_a479b_00000_0_dp=0.2000,k1=1,k2=1,k3=1,k4=3,lr=0.0158_2024-07-29_18-40-27/checkpoint_000014/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = ExVivoLRCN(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/NSQ_AC_lrcn.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSQ vs AC LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/NSQ vs AC LSTM/tune_with_parameters_78fb5_00045_45_dp=0.2000,hidden_size=300,lr=0.0034,num_layers=3_2024-07-29_17-06-11/checkpoint_000003/checkpoint.pt')\n",
    "\n",
    "# #Load Model\n",
    "model = ExVivoLSTM(\n",
    "    hidden_size=300,\n",
    "    num_layers=3,\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "# #Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/NSQ_AC_lstm.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSQ vs All Cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k23058970/miniforge3/envs/Training/lib/python3.10/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/NSQ vs All Conv/tune_with_parameters_c81ca_00002_2_dp=0.2000,k1=7,k2=1,k3=7,k4=1,lr=0.0502_2024-07-30_13-32-28/checkpoint_000003/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = ExVivoConv(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.2,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/NSQ_All_conv.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSQ vs All LRCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k23058970/miniforge3/envs/Training/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4661: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/NSQ vs All LRCN/tune_with_parameters_ea918_00001_1_dp=0.2500,k1=5,k2=1,k3=3,k4=5,lr=0.0405_2024-07-30_13-33-25/checkpoint_000009/checkpoint.pt')\n",
    "\n",
    "#Load Model\n",
    "model = ExVivoLRCN(\n",
    "    nc1=model_state['conv1.weight'].shape[0],\n",
    "    k1=model_state['conv1.weight'].shape[-1],\n",
    "    nc2=model_state['conv2.weight'].shape[0],\n",
    "    k2=model_state['conv2.weight'].shape[-1],\n",
    "    nc3=model_state['conv3.weight'].shape[0],\n",
    "    k3=model_state['conv3.weight'].shape[-1],\n",
    "    nc4=model_state['conv4.weight'].shape[0],\n",
    "    k4=model_state['conv4.weight'].shape[-1],\n",
    "    dp=0.25,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "#Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "#Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/NSQ_All_lrcn.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSQ vs All LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Model to ONNX\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#F1-score: 0.84\n",
    "#Load config\n",
    "model_state, _ = torch.load('results/NSQ vs All LSTM/tune_with_parameters_5bcb0_00002_2_dp=0.2000,hidden_size=100,lr=0.0046,num_layers=2_2024-07-30_18-15-47/checkpoint_000002/checkpoint.pt')\n",
    "\n",
    "# #Load Model\n",
    "model = ExVivoLSTM(\n",
    "    hidden_size=100,\n",
    "    num_layers=2,\n",
    "    dp=0.20,\n",
    "    l1=model_state['fc1.weight'].shape[0],\n",
    "    l2=model_state['fc2.weight'].shape[0],\n",
    "    init_input=torch.rand(1,1,891)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.to(device)\n",
    "\n",
    "# #Put Model in inference mode\n",
    "model.eval()\n",
    "\n",
    "#Creating a representative input\n",
    "batch_size = 1\n",
    "x = torch.rand(batch_size,1,891, device='cuda:0')\n",
    "\n",
    "# Model to onnx\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    x,\n",
    "    'Final Models/NSQ_All_lstm.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input':{0:'batch_size'},\n",
    "                  'output':{0:'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
